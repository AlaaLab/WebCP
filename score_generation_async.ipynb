{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 53,
   "metadata": {},
   "outputs": [],
   "source": [
    "# CHANGE THESE\n",
    "from pathlib import Path\n",
    "CONFIG_DIR = Path(\"experiment_configs/flickr-reverse-image-search_caltech-256_02-24-2024.yaml\")\n",
    "HUGGINGFACE_MODEL = 'valhalla/distilbart-mnli-12-1'#\"valhalla/distilbart-mnli-12-1\" \"facebook/bart-large-mnli\"\n",
    "NUM_THREADS = 4\n",
    "NUM_INSTANCES = 1\n",
    "INSTANCE_TYPE = \"ml.p3.2xlarge\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [],
   "source": [
    "import sys\n",
    "import os\n",
    "import zipfile\n",
    "from pathlib import Path\n",
    "import pandas as pd\n",
    "import scipy.special as sp\n",
    "import numpy as np\n",
    "from PIL import Image\n",
    "import torch\n",
    "import json\n",
    "from pathlib import Path\n",
    "import argparse\n",
    "import pickle\n",
    "import traceback\n",
    "from transformers import pipeline\n",
    "import yaml \n",
    "from multiprocessing import Pool\n",
    "from sagemaker.huggingface import HuggingFaceModel\n",
    "import urllib, time\n",
    "from botocore.exceptions import ClientError\n",
    "\n",
    "script_path = Path(os.path.dirname(os.path.abspath(sys.argv[0])))\n",
    "base_path = script_path.parent.absolute()\n",
    "sys.path.append(base_path / 'cp')\n",
    "sys.path.append(base_path / 'utils')\n",
    "from utils.pets_classes import PETS_CLASSES, PETS_GENERIC_CLASSES\n",
    "from utils.fitz17k_classes import FITZ17K_CLASSES, FITZ17K_GENERIC_CLASSES\n",
    "from utils.medmnist_classes import MEDMNIST_CLASSES, MEDMNIST_GENERIC_CLASSES\n",
    "from utils.imagenet_classes import IMAGENET_CLASSES, IMAGENET_GENERIC_CLASSES\n",
    "from utils.caltech256_classes import CALTECH256_CLASSES, CALTECH256_GENERIC_CLASSES\n",
    "\n",
    "config = {}\n",
    "with open(CONFIG_DIR, \"r\") as yaml_file:\n",
    "    config = yaml.safe_load(yaml_file)\n",
    "\n",
    "for k, v in config.items():\n",
    "    if (k[-4:] == '_dir'):\n",
    "        config[k] = Path(v)\n",
    "\n",
    "CONTEXT_DIRECTORY = Path(\"/home/sagemaker-user\") / config['reverse_image_store_dir'].name\n",
    "IMAGE_PLAUSIBILITIES = Path(\"/home/sagemaker-user\") / config['image_plausibility_store_dir'].name\n",
    "CALIB_IMAGE_DIRECTORY = Path(\"/home/sagemaker-user\") / config['scraping_store_dir'].name\n",
    "DATASET = config['dataset']\n",
    "\n",
    "if DATASET == 'MedMNIST':\n",
    "    LABELS = MEDMNIST_CLASSES\n",
    "    PSEUDO_LABELS = MEDMNIST_GENERIC_CLASSES\n",
    "elif DATASET == 'FitzPatrick17k':\n",
    "    LABELS = FITZ17K_CLASSES\n",
    "    PSEUDO_LABELS = FITZ17K_GENERIC_CLASSES\n",
    "elif DATASET == 'OxfordPets':\n",
    "    LABELS = PETS_CLASSES\n",
    "    PSEUDO_LABELS = PETS_GENERIC_CLASSES\n",
    "elif DATASET == 'ImageNet':\n",
    "    LABELS = IMAGENET_CLASSES\n",
    "    PSEUDO_LABELS = IMAGENET_GENERIC_CLASSES\n",
    "elif DATASET == \"Caltech256\":\n",
    "    LABELS = CALTECH256_CLASSES\n",
    "    PSEUDO_LABELS = CALTECH256_GENERIC_CLASSES\n",
    "else:\n",
    "    LABELS = None"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "sagemaker.config INFO - Not applying SDK defaults from location: /etc/xdg/sagemaker/config.yaml\n",
      "sagemaker.config INFO - Not applying SDK defaults from location: /home/sagemaker-user/.config/sagemaker/config.yaml\n",
      "sagemaker.config INFO - Not applying SDK defaults from location: /etc/xdg/sagemaker/config.yaml\n",
      "sagemaker.config INFO - Not applying SDK defaults from location: /home/sagemaker-user/.config/sagemaker/config.yaml\n",
      "sagemaker role arn: arn:aws:iam::475664224131:role/service-role/AmazonSageMaker-ExecutionRole-20240304T212097\n",
      "sagemaker.config INFO - Not applying SDK defaults from location: /etc/xdg/sagemaker/config.yaml\n",
      "sagemaker.config INFO - Not applying SDK defaults from location: /home/sagemaker-user/.config/sagemaker/config.yaml\n",
      "sagemaker role arn: arn:aws:iam::475664224131:role/service-role/AmazonSageMaker-ExecutionRole-20240304T212097\n",
      "sagemaker bucket: sagemaker-us-east-2-475664224131\n",
      "sagemaker session region: us-east-2\n"
     ]
    }
   ],
   "source": [
    "import sagemaker\n",
    "import boto3\n",
    "from sagemaker.async_inference.async_inference_config import AsyncInferenceConfig\n",
    "from sagemaker.s3 import s3_path_join\n",
    "from sagemaker.async_inference.waiter_config import WaiterConfig\n",
    "\n",
    "sess = sagemaker.Session()\n",
    "sagemaker_session_bucket = sess.default_bucket()\n",
    "try:\n",
    "    role = sagemaker.get_execution_role()\n",
    "except ValueError:\n",
    "    iam = boto3.client('iam')\n",
    "    role = iam.get_role(RoleName='sagemaker_execution_role')['Role']['Arn']\n",
    "\n",
    "print(f\"sagemaker role arn: {role}\")\n",
    "sess = sagemaker.Session(default_bucket=sagemaker_session_bucket)\n",
    "\n",
    "print(f\"sagemaker role arn: {role}\")\n",
    "print(f\"sagemaker bucket: {sess.default_bucket()}\")\n",
    "print(f\"sagemaker session region: {sess.boto_region_name}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "download: s3://sagemaker-datasets-hwei0/flickr_web_scraping_0224_selenium_reverse-image-search-selenium_NEW-CAPTION-METHOD_caltech-256_25size_caption-results.zip to ../flickr_web_scraping_0224_selenium_reverse-image-search-selenium_NEW-CAPTION-METHOD_caltech-256_25size_caption-results.zip\n",
      "download: s3://sagemaker-datasets-hwei0/flickr_web_scraping_0224_selenium_reverse-image-search-selenium_NEW-CAPTION-METHOD_caltech-256_25size.zip to ../flickr_web_scraping_0224_selenium_reverse-image-search-selenium_NEW-CAPTION-METHOD_caltech-256_25size.zip\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "0"
      ]
     },
     "execution_count": 20,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "os.system(f\"aws s3 cp s3://sagemaker-datasets-hwei0/{config['reverse_image_store_dir'].name}.zip /home/sagemaker-user\")\n",
    "os.system(f\"aws s3 cp s3://sagemaker-datasets-hwei0/{config['scraping_store_dir'].name}.zip /home/sagemaker-user\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [],
   "source": [
    "with zipfile.ZipFile(Path(\"/home/sagemaker-user\") / f\"{config['reverse_image_store_dir'].name}.zip\", 'r') as zip_ref:\n",
    "    zip_ref.extractall(Path(\"/home/sagemaker-user\"))\n",
    "with zipfile.ZipFile(Path(\"/home/sagemaker-user\") / f\"{config['scraping_store_dir'].name}.zip\", 'r') as zip_ref:\n",
    "    zip_ref.extractall(Path(\"/home/sagemaker-user\"))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "sagemaker.config INFO - Not applying SDK defaults from location: /etc/xdg/sagemaker/config.yaml\n",
      "sagemaker.config INFO - Not applying SDK defaults from location: /home/sagemaker-user/.config/sagemaker/config.yaml\n",
      "sagemaker.config INFO - Not applying SDK defaults from location: /etc/xdg/sagemaker/config.yaml\n",
      "sagemaker.config INFO - Not applying SDK defaults from location: /home/sagemaker-user/.config/sagemaker/config.yaml\n",
      "-----------!"
     ]
    }
   ],
   "source": [
    "# Hub model configuration <https://huggingface.co/models>\n",
    "hub = {\n",
    "  'HF_MODEL_ID':HUGGINGFACE_MODEL, # model_id from hf.co/models\n",
    "  'HF_TASK':'zero-shot-classification'                           # NLP task you want to use for predictions\n",
    "}\n",
    "# create Hugging Face Model Class\n",
    "huggingface_model = HuggingFaceModel(\n",
    "   env=hub,  # path to your trained sagemaker model\n",
    "   role=role, # iam role with permissions to create an Endpoint\n",
    "   transformers_version=\"4.26\", # transformers version used\n",
    "   pytorch_version=\"1.13\", # pytorch version used\n",
    "   py_version=\"py39\", # python version of the DLC\n",
    ")\n",
    "# Create async config\n",
    "async_config = AsyncInferenceConfig(\n",
    "    output_path=s3_path_join(\"s3://\",sagemaker_session_bucket,\"async_inference/output\")\n",
    ")\n",
    "# Create waiter config\n",
    "config = WaiterConfig(\n",
    "  max_attempts=5, \n",
    "  delay=10 \n",
    "  )\n",
    "# deploy model to SageMaker Inference\n",
    "predictor = huggingface_model.deploy(\n",
    "   initial_instance_count=NUM_INSTANCES,\n",
    "   instance_type=INSTANCE_TYPE,\n",
    "   async_inference_config=async_config\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 54,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_output(output_location):\n",
    "    output_url = urllib.parse.urlparse(output_location)\n",
    "    bucket = output_url.netloc\n",
    "    key = output_url.path[1:]\n",
    "    while True:\n",
    "        try:\n",
    "            return sess.read_s3_file(bucket=output_url.netloc, key_prefix=output_url.path[1:])\n",
    "        except ClientError as e:\n",
    "            if e.response[\"Error\"][\"Code\"] == \"NoSuchKey\":\n",
    "                time.sleep(5)\n",
    "                continue\n",
    "            raise\n",
    "def scores_converter(scores, labels):\n",
    "    dict_scores = {}\n",
    "    n = len(scores['labels'])\n",
    "    for i in range(0, n):\n",
    "        label = scores['labels'][i]\n",
    "        dict_scores[label] = scores['scores'][i]\n",
    "    score_vals = []\n",
    "    for label in labels:\n",
    "        score_vals.append(dict_scores[label])\n",
    "    return score_vals\n",
    "\n",
    "def get_score_async(predict_dict):\n",
    "    request = predictor.predict_async(predict_dict)\n",
    "    res = json.loads(get_output(request.output_path))\n",
    "    scores = scores_converter({\"scores\": res[0]['scores'], \"labels\": res[0]['labels']}, list(LABELS.values()))\n",
    "    return scores\n",
    "\n",
    "def score_generation(label):\n",
    "    print(\"Beginning Score Generation: {label}\".format(label=label))\n",
    "    os.makedirs(IMAGE_PLAUSIBILITIES / label, exist_ok=True)\n",
    "    n = 0\n",
    "    for file in os.listdir(CONTEXT_DIRECTORY / label):\n",
    "        # Load captions \n",
    "        if file.endswith(\"_debug.pkl\") or file.endswith(\"events.log\"): continue\n",
    "        try:\n",
    "            with open(CALIB_IMAGE_DIRECTORY / label / (file.split('.')[0]+'.caption'), 'r') as read:\n",
    "                title = \"\\n\".join([line.rstrip() for line in read])\n",
    "        except:\n",
    "            print('ERROR PKL LOAD')\n",
    "            print(traceback.format_exc())\n",
    "            continue\n",
    "        captions = pickle.load(open(CONTEXT_DIRECTORY / label / file, 'rb'))\n",
    "        if len(captions) <= 1: \n",
    "            print('ERROR # CAPTIONS:' + str(captions))\n",
    "            continue\n",
    "        # Main Score \n",
    "        main_score = get_score_async({\n",
    "            \"inputs\": [title],\n",
    "            \"parameters\": {'candidate_labels': list(LABELS.values()), 'multi_label': True, 'use_cache':True}\n",
    "        })\n",
    "        main_score = torch.tensor(main_score)\n",
    "        # Second Score\n",
    "        second_score = []\n",
    "        second_search = captions[0:min(10, len(captions))]\n",
    "        label_set = list(set(PSEUDO_LABELS.values()))\n",
    "        for caption in second_search:\n",
    "            score = get_score_async({\n",
    "                \"inputs\":[caption], \n",
    "                \"parameters\": {'candidate_labels': label_set, 'multi_label':True, 'use_cache':True}\n",
    "            })\n",
    "            second_score.append(score)\n",
    "            \n",
    "        second_score = [torch.tensor(score) for score in second_score]\n",
    "        second_score = torch.stack(second_score)\n",
    "        torch.save(main_score, IMAGE_PLAUSIBILITIES / label / (file.split(\".\")[0] + '_main'))\n",
    "        torch.save(second_score, IMAGE_PLAUSIBILITIES / label / (file.split(\".\")[0] + '_second'))\n",
    "        print('a')\n",
    "        n += 1\n",
    "        if n >= 10: break\n",
    "\n",
    "    sys.stdout.flush()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 50,
   "metadata": {},
   "outputs": [],
   "source": [
    "# res = predictor.predict_async({\n",
    "#             \"inputs\": [\"an image of a chair\"],\n",
    "#             \"parameters\": {'candidate_labels': list(LABELS.values()), 'multi_label': True, 'use_cache':True}\n",
    "#         })"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 51,
   "metadata": {},
   "outputs": [],
   "source": [
    "# res_out = json.loads(get_output(res.output_path))\n",
    "# scores_converter({'scores': res_out[0]['scores'], 'labels': res_out[0]['labels']}, list(LABELS.values()))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 52,
   "metadata": {},
   "outputs": [],
   "source": [
    "# res_out"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 55,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['ak47', 'american flag', 'backpack', 'baseball bat', 'baseball glove', 'basketball hoop', 'bat animal', 'bathtub', 'bear', 'beer mug', 'billiards', 'binoculars', 'birdbath', 'blimp', 'bonsai', 'boom box', 'bowling ball', 'bowling pin', 'boxing glove', 'brain', 'breadmaker', 'buddha', 'bulldozer', 'butterfly', 'cactus', 'cake', 'calculator', 'camel', 'cannon', 'canoe', 'car tire', 'cartman', 'cd', 'centipede', 'cereal box', 'chandelier', 'chess board', 'chimp', 'chopsticks', 'cockroach', 'coffee mug', 'coffin', 'coin', 'comet', 'computer keyboard', 'computer monitor', 'computer mouse', 'conch', 'cormorant', 'covered wagon', 'cowboy hat', 'crab', 'desk globe', 'diamond ring', 'dice', 'dog', 'dolphin', 'doorknob', 'drinking straw', 'duck', 'dumb bell', 'eiffel tower', 'electric guitar', 'elephant', 'elk', 'ewer', 'eyeglasses', 'fern', 'fighter jet', 'fire extinguisher', 'fire hydrant', 'fire truck', 'fireworks', 'flashlight', 'floppy disk', 'football helmet', 'french horn', 'fried egg', 'frisbee', 'frog', 'frying pan', 'galaxy', 'gas pump', 'giraffe', 'goat', 'golden gate bridge', 'goldfish', 'golf ball', 'goose', 'gorilla', 'grand piano', 'grapes', 'grasshopper', 'guitar pick', 'hamburger', 'hammock', 'harmonica', 'harp', 'harpsichord', 'hawksbill', 'head phones', 'helicopter', 'hibiscus', 'homer simpson', 'horse', 'horseshoe crab', 'hot air balloon', 'hot dog', 'hot tub', 'hourglass', 'house fly', 'human skeleton', 'hummingbird', 'ibis', 'ice cream cone', 'iguana', 'ipod', 'iris', 'jesus christ', 'joy stick', 'kangaroo', 'kayak', 'ketch', 'killer whale', 'knife', 'ladder', 'laptop', 'lathe', 'leopards', 'license plate', 'lightbulb', 'light house', 'lightning', 'llama', 'mailbox', 'mandolin', 'mars', 'mattress', 'megaphone', 'menorah', 'microscope', 'microwave', 'minaret', 'minotaur', 'motorbikes', 'mountain bike', 'mushroom', 'mussels', 'necktie', 'octopus', 'ostrich', 'owl', 'palm pilot', 'palm tree', 'paperclip', 'paper shredder', 'pci card', 'penguin', 'people', 'pez dispenser', 'photocopier', 'picnic table', 'playing card', 'porcupine', 'pram', 'praying mantis', 'pyramid', 'raccoon', 'radio telescope', 'rainbow', 'refrigerator', 'revolver', 'rifle', 'rotary phone', 'roulette wheel', 'saddle', 'saturn', 'school bus', 'scorpion', 'screwdriver', 'segway', 'self propelled lawn mower', 'sextant', 'sheet music', 'skateboard', 'skunk', 'skyscraper', 'smokestack', 'snail', 'snake', 'sneaker', 'snowmobile', 'soccer ball', 'socks', 'soda can', 'spaghetti', 'speed boat', 'spider', 'spoon', 'stained glass', 'starfish', 'steering wheel', 'stirrups', 'sunflower', 'superman', 'sushi', 'swan', 'swiss army knife', 'sword', 'syringe', 'tambourine', 'teapot', 'teddy bear', 'teepee', 'telephone box', 'tennis ball', 'tennis court', 'tennis racket', 'theodolite', 'toaster', 'tomato', 'tombstone', 'top hat', 'touring bike', 'tower pisa', 'traffic light', 'treadmill', 'triceratops', 'tricycle', 'trilobite', 'tripod', 't shirt', 'tuning fork', 'tweezer', 'umbrella', 'unicorn', 'vcr', 'video projector', 'washing machine', 'watch', 'waterfall', 'watermelon', 'welding mask', 'wheelbarrow', 'windmill', 'wine bottle', 'xylophone', 'yarmulke', 'yo yo', 'zebra', 'airplanes', 'car side', 'faces easy', 'greyhound', 'tennis shoes', 'toad', 'clutter']\n",
      "Beginning Score Generation: 0\n",
      "Beginning Score Generation: 17Beginning Score Generation: 34\n",
      "\n",
      "Beginning Score Generation: 51\n",
      "a\n",
      "a\n",
      "a\n",
      "a\n",
      "a\n",
      "a\n",
      "a\n",
      "a\n",
      "a\n",
      "a\n",
      "a\n",
      "a\n",
      "a\n",
      "ERROR # CAPTIONS:['GIF Kalashnikov Firing | Click all sizes to see the magic. | Flickr from Flickr']\n",
      "a\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "KeyboardInterrupt\n",
      "\n"
     ]
    }
   ],
   "source": [
    "\n",
    "\n",
    "# Encode Labels\n",
    "#label_embed = model.encode([label for label in LABELS.values()])\n",
    "labels = [label.split(',')[0] for label in LABELS.values()]\n",
    "print(labels)\n",
    "#pseudo_embed = model.encode([label for label in PSEUDO_LABELS.values()])\n",
    "# Loop through caption folders\n",
    "dir_labels = []\n",
    "for label in os.listdir(CONTEXT_DIRECTORY):\n",
    "    try: \n",
    "        int(label)\n",
    "    except:\n",
    "        continue\n",
    "    if label.endswith(\"events.log\"): \n",
    "        continue\n",
    "    dir_labels.append(label)\n",
    "\n",
    "with Pool(processes=NUM_THREADS) as executor:\n",
    "    executor.map(score_generation, dir_labels)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 56,
   "metadata": {},
   "outputs": [],
   "source": [
    "# delete endpoint\n",
    "predictor.delete_model()\n",
    "predictor.delete_endpoint()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "os.system(f\"aws s3 cp {IMAGE_PLAUSIBILITIES.resolve()} s3://sagemaker-datasets-hwei0 --recursive\")"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.13"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}

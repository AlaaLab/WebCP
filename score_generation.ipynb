{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# CHANGE THESE\n",
    "CONFIG_DIR = Path()\n",
    "HUGGINGFACE_MODEL = 'valhalla/distilbart-mnli-12-1'#\"valhalla/distilbart-mnli-12-1\" \"facebook/bart-large-mnli\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import sys\n",
    "import os\n",
    "import zipfile\n",
    "from pathlib import Path\n",
    "import pandas as pd\n",
    "import scipy.special as sp\n",
    "import numpy as np\n",
    "from PIL import Image\n",
    "import torch\n",
    "import open_clip\n",
    "import json\n",
    "from pathlib import Path\n",
    "import argparse\n",
    "import pickle\n",
    "import traceback\n",
    "from transformers import pipeline\n",
    "from sentence_transformers import SentenceTransformer, util\n",
    "import yaml \n",
    "from multiprocessing import Pool\n",
    "from sagemaker.huggingface import HuggingFaceModel\n",
    "\n",
    "script_path = Path(os.path.dirname(os.path.abspath(sys.argv[0])))\n",
    "base_path = script_path.parent.absolute()\n",
    "sys.path.append(base_path / 'cp')\n",
    "sys.path.append(base_path / 'utils')\n",
    "from utils.pets_classes import PETS_CLASSES, PETS_GENERIC_CLASSES\n",
    "from utils.fitz17k_classes import FITZ17K_CLASSES, FITZ17K_GENERIC_CLASSES\n",
    "from utils.medmnist_classes import MEDMNIST_CLASSES, MEDMNIST_GENERIC_CLASSES\n",
    "from utils.imagenet_classes import IMAGENET_CLASSES, IMAGENET_GENERIC_CLASSES\n",
    "from utils.caltech256_classes import CALTECH256_CLASSES, CALTECH256_GENERIC_CLASSES\n",
    "\n",
    "config = {}\n",
    "with open(CONFIG_DIR, \"r\") as yaml_file:\n",
    "    config = yaml.safe_load(yaml_file)\n",
    "\n",
    "for k, v in config.items():\n",
    "    if (k[-4:] == '_dir'):\n",
    "        config[k] = Path(v)\n",
    "\n",
    "CONTEXT_DIRECTORY = Path(\"/home/sagemaker-user\") / config['reverse_image_store_dir'].name\n",
    "IMAGE_PLAUSIBILITIES = Path(\"/home/sagemaker-user\") / config['image_plausibility_store_dir'].name\n",
    "CALIB_IMAGE_DIRECTORY = Path(\"/home/sagemaker-user\") / config['scraping_store_dir'].name\n",
    "DATASET = config['dataset']\n",
    "\n",
    "if DATASET == 'MedMNIST':\n",
    "    LABELS = MEDMNIST_CLASSES\n",
    "    PSEUDO_LABELS = MEDMNIST_GENERIC_CLASSES\n",
    "elif DATASET == 'FitzPatrick17k':\n",
    "    LABELS = FITZ17K_CLASSES\n",
    "    PSEUDO_LABELS = FITZ17K_GENERIC_CLASSES\n",
    "elif DATASET == 'OxfordPets':\n",
    "    LABELS = PETS_CLASSES\n",
    "    PSEUDO_LABELS = PETS_GENERIC_CLASSES\n",
    "elif DATASET == 'ImageNet':\n",
    "    LABELS = IMAGENET_CLASSES\n",
    "    PSEUDO_LABELS = IMAGENET_GENERIC_CLASSES\n",
    "elif DATASET == \"Caltech256\":\n",
    "    LABELS = CALTECH256_CLASSES\n",
    "    PSEUDO_LABELS = CALTECH256_GENERIC_CLASSES\n",
    "else:\n",
    "    LABELS = None"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import sagemaker\n",
    "import boto3\n",
    "\n",
    "try:\n",
    "    role = sagemaker.get_execution_role()\n",
    "except ValueError:\n",
    "    iam = boto3.client('iam')\n",
    "    role = iam.get_role(RoleName='sagemaker_execution_role')['Role']['Arn']\n",
    "\n",
    "print(f\"sagemaker role arn: {role}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "os.system(f\"aws s3 cp s3://sagemaker-datasets-hwei0/{config['reverse_image_store_dir'].name}.zip /home/sagemaker-user --recursive\")\n",
    "os.system(f\"aws s3 cp s3://sagemaker-datasets-hwei0/{config['scraping_store_dir'].name}.zip /home/sagemaker-user --recursive\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "with zipfile.ZipFile(Path(\"/home/sagemaker-user\") / f\"{config['reverse_image_store_dir'].name}.zip\", 'r') as zip_ref:\n",
    "    zip_ref.extractall(Path(\"/home/sagemaker-user\"))\n",
    "with zipfile.ZipFile(Path(\"/home/sagemaker-user\") / f\"{config['scraping_store_dir'].name}.zip\", 'r') as zip_ref:\n",
    "    zip_ref.extractall(Path(\"/home/sagemaker-user\"))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Hub model configuration <https://huggingface.co/models>\n",
    "hub = {\n",
    "  'HF_MODEL_ID':HUGGINGFACE_MODEL, # model_id from hf.co/models\n",
    "  'HF_TASK':'zero-shot-classification'                           # NLP task you want to use for predictions\n",
    "}\n",
    "# create Hugging Face Model Class\n",
    "huggingface_model = HuggingFaceModel(\n",
    "   env=hub,  # path to your trained sagemaker model\n",
    "   role=role, # iam role with permissions to create an Endpoint\n",
    "   transformers_version=\"4.26\", # transformers version used\n",
    "   pytorch_version=\"1.13\", # pytorch version used\n",
    "   py_version=\"py39\", # python version of the DLC\n",
    ")\n",
    "# deploy model to SageMaker Inference\n",
    "predictor = huggingface_model.deploy(\n",
    "   initial_instance_count=1,\n",
    "   instance_type=\"ml.m5.xlarge\"\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "def scores_converter(scores, labels):\n",
    "    dict_scores = {}\n",
    "    n = len(scores['labels'])\n",
    "    for i in range(0, n):\n",
    "        label = scores['labels'][i]\n",
    "        dict_scores[label] = scores['scores'][i]\n",
    "    score_vals = []\n",
    "    for label in labels:\n",
    "        score_vals.append(dict_scores[label])\n",
    "    return score_vals\n",
    "\n",
    "def score_generation(label):\n",
    "    print(\"Beginning Score Generation: {label}\".format(label=label))\n",
    "    os.makedirs(IMAGE_PLAUSIBILITIES / label, exist_ok=True)\n",
    "    n = 0\n",
    "    for file in os.listdir(CONTEXT_DIRECTORY / label):\n",
    "        # Load captions \n",
    "        if file.endswith(\"_debug.pkl\") or file.endswith(\"events.log\"): continue\n",
    "        try:\n",
    "            with open(CALIB_IMAGE_DIRECTORY / label / (file.split('.')[0]+'.caption'), 'r') as read:\n",
    "                title = \"\\n\".join([line.rstrip() for line in read])\n",
    "        except:\n",
    "            print('ERROR PKL LOAD')\n",
    "            print(traceback.format_exc())\n",
    "            continue\n",
    "        captions = pickle.load(open(CONTEXT_DIRECTORY / label / file, 'rb'))\n",
    "        if len(captions) <= 1: \n",
    "            print('ERROR # CAPTIONS:' + str(captions))\n",
    "            continue\n",
    "        # Main Score \n",
    "        main_score = predictor.predict({\n",
    "            \"inputs\": [title],\n",
    "            \"parameters\": {'candidate_labels': list(LABELS.values()), 'multi_label': True, 'use_cache':True}\n",
    "        })\n",
    "        main_score = scores_converter(main_score, list(LABELS.values()))\n",
    "        main_score = torch.tensor(main_score)\n",
    "        # Second Score\n",
    "        second_score = []\n",
    "        second_search = captions[0:min(10, len(captions))]\n",
    "        label_set = list(set(PSEUDO_LABELS.values()))\n",
    "        for caption in second_search:\n",
    "            score_dict = predictor.predict({\n",
    "                \"inputs\":[caption], \n",
    "                \"parameters\": {'candidate_labels': label_set, 'multi_label':True, 'use_cache':True}\n",
    "            })\n",
    "            score = scores_converter(score_dict, list(PSEUDO_LABELS.values()))\n",
    "            second_score.append(score)\n",
    "        second_score = [torch.tensor(score) for score in second_score]\n",
    "        second_score = torch.stack(second_score)\n",
    "        torch.save(main_score, IMAGE_PLAUSIBILITIES / label / (file.split(\".\")[0] + '_main'))\n",
    "        torch.save(second_score, IMAGE_PLAUSIBILITIES / label / (file.split(\".\")[0] + '_second'))\n",
    "        print('a')\n",
    "        n += 1\n",
    "        if n >= 10: break\n",
    "\n",
    "    sys.stdout.flush()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "\n",
    "# Encode Labels\n",
    "#label_embed = model.encode([label for label in LABELS.values()])\n",
    "labels = [label.split(',')[0] for label in LABELS.values()]\n",
    "print(labels)\n",
    "#pseudo_embed = model.encode([label for label in PSEUDO_LABELS.values()])\n",
    "# Loop through caption folders\n",
    "dir_labels = []\n",
    "for label in os.listdir(CONTEXT_DIRECTORY):\n",
    "    try: \n",
    "        int(label)\n",
    "    except:\n",
    "        continue\n",
    "    if label.endswith(\"events.log\"): \n",
    "        continue\n",
    "    dir_labels.append(label)\n",
    "\n",
    "with Pool(processes=config['num_selenium_threads']) as executor:\n",
    "    executor.map(score_generation, dir_labels)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "os.system(f\"aws s3 cp {IMAGE_PLAUSIBILITIES.resolve()} s3://sagemaker-datasets-hwei0 --recursive\")"
   ]
  }
 ],
 "metadata": {
  "language_info": {
   "name": "python"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
